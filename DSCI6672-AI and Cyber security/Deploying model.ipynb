{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 - Training: \n",
    "In this task, you will be creating and training a deep neural network based on the\n",
    "MalConv architecture to classify PE files as malware or benign. As for the dataset, you will be using the\n",
    "EMBER-2017 v2 ( https://github.com/endgameinc/ember ). Besides the references provided in this\n",
    "repository, the following two talks at BSides San Francisco 2018 and the CAMLIS 2019 conferences\n",
    "present detailed overviews of this dataset, as well as hints on how to use EMBER to train malware\n",
    "classifiers:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\gouru\\anaconda3\\lib\\site-packages (1.18.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\gouru\\anaconda3\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from pandas) (1.18.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from python-dateutil>=2.6.1->pandas) (1.14.0)\n",
      "Requirement already satisfied: keras in c:\\users\\gouru\\anaconda3\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: h5py in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from keras) (1.14.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from keras) (1.18.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from keras) (5.3)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\gouru\\anaconda3\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from tensorflow) (3.11.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: gast==0.2.2 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.2)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from tensorflow) (1.28.1)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from tensorflow) (0.34.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from tensorflow) (0.8.1)\n",
      "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from tensorflow) (2.0.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from tensorflow) (1.18.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from tensorflow) (3.2.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from tensorflow) (1.0.8)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from tensorflow) (0.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from protobuf>=3.6.1->tensorflow) (45.2.0.post20200210)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (1.14.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (3.2.1)\n",
      "Requirement already satisfied: h5py in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from keras-applications>=1.0.8->tensorflow) (2.10.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (4.1.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.4.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: sklearn in c:\\users\\gouru\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from sklearn) (0.22.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.18.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (0.14.1)\n",
      "Requirement already satisfied: altair in c:\\users\\gouru\\anaconda3\\lib\\site-packages (4.1.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from altair) (2.11.1)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from altair) (0.3)\n",
      "Requirement already satisfied: pandas>=0.18 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from altair) (1.0.1)\n",
      "Requirement already satisfied: jsonschema in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from altair) (3.2.0)\n",
      "Requirement already satisfied: toolz in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from altair) (0.10.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from altair) (1.18.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from jinja2->altair) (1.1.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from pandas>=0.18->altair) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from pandas>=0.18->altair) (2.8.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from jsonschema->altair) (19.3.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from jsonschema->altair) (0.15.7)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from jsonschema->altair) (1.14.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from jsonschema->altair) (1.5.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from jsonschema->altair) (45.2.0.post20200210)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema->altair) (2.2.0)\n",
      "Requirement already satisfied: altair in c:\\users\\gouru\\anaconda3\\lib\\site-packages (4.1.0)\n",
      "Requirement already satisfied: vega_datasets in c:\\users\\gouru\\anaconda3\\lib\\site-packages (0.8.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from altair) (1.18.1)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from altair) (0.3)\n",
      "Requirement already satisfied: jsonschema in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from altair) (3.2.0)\n",
      "Requirement already satisfied: pandas>=0.18 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from altair) (1.0.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from altair) (2.11.1)\n",
      "Requirement already satisfied: toolz in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from altair) (0.10.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from jsonschema->altair) (0.15.7)\n",
      "Requirement already satisfied: setuptools in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from jsonschema->altair) (45.2.0.post20200210)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from jsonschema->altair) (1.5.0)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from jsonschema->altair) (1.14.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from jsonschema->altair) (19.3.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from pandas>=0.18->altair) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from pandas>=0.18->altair) (2.8.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from jinja2->altair) (1.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema->altair) (2.2.0)\n",
      "Requirement already satisfied: tensorflow==2.0 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from tensorflow==2.0) (0.9.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from tensorflow==2.0) (3.2.1)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from tensorflow==2.0) (3.11.3)\n",
      "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from tensorflow==2.0) (2.0.2)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from tensorflow==2.0) (1.11.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from tensorflow==2.0) (1.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from tensorflow==2.0) (0.2.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from tensorflow==2.0) (1.1.0)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from tensorflow==2.0) (0.34.2)\n",
      "Requirement already satisfied: gast==0.2.2 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from tensorflow==2.0) (0.2.2)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from tensorflow==2.0) (1.14.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from tensorflow==2.0) (1.28.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from tensorflow==2.0) (2.0.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from tensorflow==2.0) (1.0.8)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from tensorflow==2.0) (1.18.1)\n",
      "Requirement already satisfied: astor>=0.6.0 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from tensorflow==2.0) (0.8.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from protobuf>=3.6.1->tensorflow==2.0) (45.2.0.post20200210)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (2.22.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (1.0.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (1.14.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.2.1)\n",
      "Requirement already satisfied: h5py in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from keras-applications>=1.0.8->tensorflow==2.0) (2.10.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (1.3.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (1.25.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.0.4)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (4.1.0)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.4.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.2.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install keras\n",
    "!pip install tensorflow\n",
    "!pip install sklearn\n",
    "!pip install altair\n",
    "!pip install altair vega_datasets\n",
    "\n",
    "\n",
    "!pip install tensorflow==2.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: js.ember in c:\\users\\gouru\\anaconda3\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from js.ember) (45.2.0.post20200210)\n",
      "Requirement already satisfied: fanstatic in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from js.ember) (1.1)\n",
      "Requirement already satisfied: js.jquery>=1.9.1 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from js.ember) (3.3.1)\n",
      "Requirement already satisfied: shutilwhich in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from fanstatic->js.ember) (1.1.0)\n",
      "Requirement already satisfied: WebOb>=1.2 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from fanstatic->js.ember) (1.8.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install js.ember"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the Vectorized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 900000/900000 [11:31<00:00, 1301.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 200000/200000 [02:34<00:00, 1291.92it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sha256</th>\n",
       "      <th>appeared</th>\n",
       "      <th>subset</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0abb4fda7d5b13801d63bee53e5e256be43e141faa077a...</td>\n",
       "      <td>2006-12</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d4206650743b3d519106dea10a38a55c30467c3d9f7875...</td>\n",
       "      <td>2006-12</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c9cafff8a596ba8a80bafb4ba8ae6f2ef3329d95b85f15...</td>\n",
       "      <td>2007-01</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7f513818bcc276c531af2e641c597744da807e21cc1160...</td>\n",
       "      <td>2007-02</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ca65e1c387a4cc9e7d8a8ce12bf1bcf9f534c9032b9d95...</td>\n",
       "      <td>2007-02</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099995</th>\n",
       "      <td>fffe314f23cee3a68ccab272934877d3bc18ec3bd905df...</td>\n",
       "      <td>2017-12</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099996</th>\n",
       "      <td>fffe7a1b23e04facc9ca91a93ac4a34e8b3040e023dbde...</td>\n",
       "      <td>2017-12</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099997</th>\n",
       "      <td>fffe801f51e7ec931515aa49a3d157a9c0fbcdca8c9d80...</td>\n",
       "      <td>2017-12</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099998</th>\n",
       "      <td>fffe92f9593649c4a7050302368189de45e2c1c06b04ea...</td>\n",
       "      <td>2017-12</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099999</th>\n",
       "      <td>ffffb259a4c5e25ae1437af59caafb718cf8879187cc8c...</td>\n",
       "      <td>2017-12</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1100000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    sha256 appeared subset  \\\n",
       "0        0abb4fda7d5b13801d63bee53e5e256be43e141faa077a...  2006-12  train   \n",
       "1        d4206650743b3d519106dea10a38a55c30467c3d9f7875...  2006-12  train   \n",
       "2        c9cafff8a596ba8a80bafb4ba8ae6f2ef3329d95b85f15...  2007-01  train   \n",
       "3        7f513818bcc276c531af2e641c597744da807e21cc1160...  2007-02  train   \n",
       "4        ca65e1c387a4cc9e7d8a8ce12bf1bcf9f534c9032b9d95...  2007-02  train   \n",
       "...                                                    ...      ...    ...   \n",
       "1099995  fffe314f23cee3a68ccab272934877d3bc18ec3bd905df...  2017-12   test   \n",
       "1099996  fffe7a1b23e04facc9ca91a93ac4a34e8b3040e023dbde...  2017-12   test   \n",
       "1099997  fffe801f51e7ec931515aa49a3d157a9c0fbcdca8c9d80...  2017-12   test   \n",
       "1099998  fffe92f9593649c4a7050302368189de45e2c1c06b04ea...  2017-12   test   \n",
       "1099999  ffffb259a4c5e25ae1437af59caafb718cf8879187cc8c...  2017-12   test   \n",
       "\n",
       "         label  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  \n",
       "...        ...  \n",
       "1099995      0  \n",
       "1099996      1  \n",
       "1099997      0  \n",
       "1099998      1  \n",
       "1099999      1  \n",
       "\n",
       "[1100000 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ember\n",
    "ember.create_vectorized_features(\"C:\\\\Users\\\\gouru\\\\Downloads\\\\ember_2017_2\")\n",
    "ember.create_metadata(\"C:\\\\Users\\\\gouru\\\\Downloads\\\\ember_2017_2\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gouru\\anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = ember.read_vectorized_features(\"C:\\\\Users\\\\gouru\\\\Downloads\\\\ember_2017_2\")\n",
    "metadata_dataframe = ember.read_metadata(\"C:\\\\Users\\\\gouru\\\\Downloads\\\\ember_2017_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sha256</th>\n",
       "      <th>appeared</th>\n",
       "      <th>subset</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1099995</th>\n",
       "      <td>fffe314f23cee3a68ccab272934877d3bc18ec3bd905df...</td>\n",
       "      <td>2017-12</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099996</th>\n",
       "      <td>fffe7a1b23e04facc9ca91a93ac4a34e8b3040e023dbde...</td>\n",
       "      <td>2017-12</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099997</th>\n",
       "      <td>fffe801f51e7ec931515aa49a3d157a9c0fbcdca8c9d80...</td>\n",
       "      <td>2017-12</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099998</th>\n",
       "      <td>fffe92f9593649c4a7050302368189de45e2c1c06b04ea...</td>\n",
       "      <td>2017-12</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099999</th>\n",
       "      <td>ffffb259a4c5e25ae1437af59caafb718cf8879187cc8c...</td>\n",
       "      <td>2017-12</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    sha256 appeared subset  \\\n",
       "1099995  fffe314f23cee3a68ccab272934877d3bc18ec3bd905df...  2017-12   test   \n",
       "1099996  fffe7a1b23e04facc9ca91a93ac4a34e8b3040e023dbde...  2017-12   test   \n",
       "1099997  fffe801f51e7ec931515aa49a3d157a9c0fbcdca8c9d80...  2017-12   test   \n",
       "1099998  fffe92f9593649c4a7050302368189de45e2c1c06b04ea...  2017-12   test   \n",
       "1099999  ffffb259a4c5e25ae1437af59caafb718cf8879187cc8c...  2017-12   test   \n",
       "\n",
       "         label  \n",
       "1099995      0  \n",
       "1099996      1  \n",
       "1099997      0  \n",
       "1099998      1  \n",
       "1099999      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_dataframe.tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing the data and taking relevant samples:\n",
    "I tried doing without normalizing and the accuracy of the model is about 41%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelrows = (y_train != -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[labelrows]\n",
    "y_train = y_train[labelrows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "for x in range(0,600000,100000):\n",
    "    ss.partial_fit(X_train[x:x+100000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = ss.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers, Input, Model\n",
    "from keras.layers import Dense, Conv1D, Activation, GlobalMaxPooling1D, Input, Embedding, Multiply\n",
    "from keras.models import Model, load_model\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import optimizers\n",
    "maxLen = 200000\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model():\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras import layers\n",
    "    feature_size=2381\n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "    keras.backend.clear_session()\n",
    "  \n",
    "    #Model architecture\n",
    "    from tensorflow.keras import layers\n",
    "  \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.InputLayer(input_shape=(1,feature_size)))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(1500, activation='relu',activity_regularizer=tf.keras.regularizers.l1(l=0.01)))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy',tf.keras.metrics.AUC(),tf.keras.metrics.Precision()])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\gouru\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dropout (Dropout)            (None, 1, 2381)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1, 1500)           3573000   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 1500)           0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1, 1)              1501      \n",
      "=================================================================\n",
      "Total params: 3,574,501\n",
      "Trainable params: 3,574,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_train = np.reshape(X_train,(-1,1,2381))\n",
    "y_train = np.reshape(y_train,(-1,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480000 samples, validate on 120000 samples\n",
      "Epoch 1/5\n",
      "480000/480000 [==============================] - 117s 243us/sample - loss: 23.9837 - accuracy: 0.9167 - auc_1: 0.9340 - precision_1: 0.9146 - val_loss: 65.5862 - val_accuracy: 0.9670 - val_auc_1: 0.9798 - val_precision_1: 0.9822\n",
      "Epoch 2/5\n",
      "480000/480000 [==============================] - 110s 230us/sample - loss: 23.1052 - accuracy: 0.9310 - auc_1: 0.9481 - precision_1: 0.9265 - val_loss: 50.7621 - val_accuracy: 0.9693 - val_auc_1: 0.9811 - val_precision_1: 0.9728\n",
      "Epoch 3/5\n",
      "480000/480000 [==============================] - 108s 224us/sample - loss: 12.6532 - accuracy: 0.9249 - auc_1: 0.9530 - precision_1: 0.9113 - val_loss: 36.6807 - val_accuracy: 0.9598 - val_auc_1: 0.9831 - val_precision_1: 0.9575\n",
      "Epoch 4/5\n",
      "480000/480000 [==============================] - 154s 321us/sample - loss: 8.9409 - accuracy: 0.9035 - auc_1: 0.9507 - precision_1: 0.8731 - val_loss: 23.1465 - val_accuracy: 0.9440 - val_auc_1: 0.9839 - val_precision_1: 0.9226\n",
      "Epoch 5/5\n",
      "480000/480000 [==============================] - 155s 324us/sample - loss: 11.3801 - accuracy: 0.8822 - auc_1: 0.9408 - precision_1: 0.8529 - val_loss: 20.9932 - val_accuracy: 0.9577 - val_auc_1: 0.9828 - val_precision_1: 0.9482\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "model.compile(tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "          loss='binary_crossentropy',\n",
    "          metrics=['accuracy',tf.keras.metrics.AUC(),tf.keras.metrics.Precision()])\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                batch_size=128,\n",
    "                epochs=5,\n",
    "                  validation_split=.2,\n",
    "                  callbacks=None )\n",
    "                  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.reshape(X_test,(-1,1,2381))\n",
    "y_test = np.reshape(y_test,(-1,1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 45s 223us/sample - loss: 616.1691 - accuracy: 0.9444 - auc_1: 0.9734 - precision_1: 0.9273\n",
      "loss: 616.169l,acc: 0.944365l\n"
     ]
    }
   ],
   "source": [
    "results =model.evaluate(X_test,y_test)\n",
    "print(\"loss: %gl,acc: %gl\"%(results[0],results[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.reshape(y_test,(-1))\n",
    "y_pred = np.reshape(y_pred,(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "False positive rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "def get_fpr(y_test, y_pred):\n",
    "    nbenign = (y_test == 0).sum()\n",
    "    nfalse = (y_pred[y_test == 0] == 1).sum()\n",
    "    return nfalse / float(nbenign)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00613"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_fpr(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_int = np.asarray(y_test,dtype=int)\n",
    "y_pred_int=np.asarray(y_pred,dtype=int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7965743880486332"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "fscore = f1_score(y_test_int, y_pred_int) \n",
    "fscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9908794691345166"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "precision = sklearn.metrics.precision_score(y_test_int,y_pred_int)\n",
    "precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confmat = confusion_matrix(y_test_int,y_pred_int,labels=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[99387,   613],\n",
       "       [33402, 66598]], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: h5py in c:\\users\\gouru\\anaconda3\\lib\\site-packages (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.7 in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from h5py) (1.18.1)\n",
      "Requirement already satisfied: six in c:\\users\\gouru\\anaconda3\\lib\\site-packages (from h5py) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "!pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "save_path = \"C:\\\\Users\\\\gouru\\\\Downloads\\\\ember_2017_2\"\n",
    "\n",
    "model.save_weights(os.path.join(save_path,\"my_weights.h5\"))\n",
    "\n",
    "# save neural network structure to JSON (no weights)\n",
    "model_json = model.to_json()\n",
    "with open(os.path.join(save_path,\"my_model.json\"), \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up and load the Keras model using the json and weights file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3, re\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/__init__.py:1467: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir keras_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_model.json  my_weights.h5\r\n"
     ]
    }
   ],
   "source": [
    "!ls keras_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:131: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "json_file = open('/home/ec2-user/SageMaker/keras_model/'+'my_model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json,custom_objects={\"GlorotUniform\": tf.keras.initializers.glorot_uniform})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:184: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "loaded_model.load_weights('/home/ec2-user/SageMaker/keras_model/my_weights.h5')\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export the Keras model to the TensorFlow ProtoBuf format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.saved_model import builder\n",
    "from tensorflow.python.saved_model.signature_def_utils import predict_signature_def\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "\n",
    "# Note: This directory structure will need to be followed - see notes for the next section\n",
    "model_version = '1'\n",
    "export_dir = 'export/Servo/' + model_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import shutil\n",
    "shutil.rmtree(export_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Protocol Buffer SavedModel at 'export_dir'\n",
    "build = builder.SavedModelBuilder(export_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create prediction signature to be used by TensorFlow Serving Predict API\n",
    "signature = predict_signature_def(\n",
    "    inputs={\"inputs\": loaded_model.input}, outputs={\"score\": loaded_model.output})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: export/Servo/1/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "with K.get_session() as sess:\n",
    "    # Save the meta graph and variables\n",
    "    build.add_meta_graph_and_variables(\n",
    "        sess=sess, tags=[tag_constants.SERVING], signature_def_map={\"serving_default\": signature})\n",
    "    build.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert TensorFlow model to a SageMaker readable format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Servo\r\n"
     ]
    }
   ],
   "source": [
    "!ls export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!ls export/Servo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variables.data-00000-of-00001  variables.index\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!ls export/Servo/1/variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "with tarfile.open('model.tar.gz', mode='w:gz') as archive:\n",
    "    archive.add('export', recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "inputs = sagemaker_session.upload_data(path='model.tar.gz', key_prefix='model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy the trained model (must use AWS SageMaker Notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "!touch train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2.1.0 is the latest version of tensorflow that supports Python 2. Newer versions of tensorflow will only be available for Python 3.Please set the argument \"py_version='py3'\" to use the Python 3 tensorflow image.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.tensorflow.model import TensorFlowModel\n",
    "sagemaker_model = TensorFlowModel(model_data = 's3://' + sagemaker_session.default_bucket() + '/model/model.tar.gz',\n",
    "                                  role = role,\n",
    "                                  framework_version = '1.12',\n",
    "                                  entry_point = 'train.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!CPU times: user 462 ms, sys: 21.8 ms, total: 483 ms\n",
      "Wall time: 6min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictor = sagemaker_model.deploy(initial_instance_count=1,\n",
    "                                   instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sagemaker-tensorflow-2020-04-28-00-12-37-103'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = 'sagemaker-tensorflow-2020-04-28-00-12-37-103'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.tensorflow.model import TensorFlowModel\n",
    "predictor=sagemaker.tensorflow.model.TensorFlowPredictor(endpoint_name, sagemaker_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "endpoint_name = 'sagemaker-tensorflow-2020-04-28-00-12-37-103'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
